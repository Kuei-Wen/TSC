import os
import sys
import wave
import json
import subprocess
from vosk import Model, KaldiRecognizer

# --- è¨­å®š ---
# æŒ‡å‘æ‚¨ä¸‹è¼‰ä¸¦è§£å£“ç¸®å¾Œçš„ Vosk æ¨¡å‹è³‡æ–™å¤¾
"""
FFmpeg æ˜¯ä¸€å€‹å‘½ä»¤åˆ—å·¥å…·ï¼Œä¸æ˜¯ Python å¥—ä»¶ã€‚æ‚¨éœ€è¦å¾å®˜ç¶²ä¸‹è¼‰ä¸¦å®‰è£å®ƒã€‚
ä¸‹è¼‰é é¢ï¼šhttps://ffmpeg.org/download.html
é‡è¦ï¼šå®‰è£å¾Œï¼Œè«‹ç¢ºä¿å°‡ ffmpeg çš„åŸ·è¡Œæª”è·¯å¾‘åŠ å…¥åˆ°æ‚¨ç³»çµ±çš„ç’°å¢ƒè®Šæ•¸ PATH ä¸­ï¼Œé€™æ¨£ Python æ‰èƒ½åœ¨ä»»ä½•è·¯å¾‘ä¸‹å‘¼å«å®ƒã€‚æ‚¨å¯ä»¥åœ¨çµ‚ç«¯æ©Ÿ/å‘½ä»¤æç¤ºå­—å…ƒä¸­è¼¸å…¥ ffmpeg -version ä¾†æ¸¬è©¦æ˜¯å¦å®‰è£æˆåŠŸã€‚
2. å®‰è£ Python çš„ vosk å¥—ä»¶

pip install vosk
3. ä¸‹è¼‰ Vosk èªéŸ³æ¨¡å‹

Vosk éœ€è¦ä¸€å€‹é å…ˆè¨“ç·´å¥½çš„æ¨¡å‹ä¾†é€²è¡Œè¾¨è­˜ã€‚è«‹å‰å¾€ Vosk æ¨¡å‹é é¢ä¸‹è¼‰ã€‚
æ¨¡å‹ä¸‹è¼‰é é¢ï¼šhttps://alphacephei.com/vosk/models
ç‚ºäº†ç²å¾—è¼ƒå¥½çš„ä¸­æ–‡è¾¨è­˜æ•ˆæœï¼Œå»ºè­°ä¸‹è¼‰è¼ƒå¤§çš„æ¨¡å‹ï¼Œä¾‹å¦‚ vosk-model-cn-0.22 (ç´„ 1.9 GB) æˆ–æ›´é©åˆå°ç£å£éŸ³çš„ vosk-model-small-tw-rh-0.4 (45MB)ã€‚
ä¸‹è¼‰å¾Œè§£å£“ç¸®ï¼Œæœƒå¾—åˆ°ä¸€å€‹è³‡æ–™å¤¾ï¼ˆä¾‹å¦‚ vosk-model-cn-0.22ï¼‰ï¼Œè«‹å°‡é€™å€‹è³‡æ–™å¤¾èˆ‡æ‚¨çš„ Python è…³æœ¬æ”¾åœ¨åŒä¸€å€‹ç›®éŒ„ä¸‹ï¼Œæˆ–åœ¨ç¨‹å¼ç¢¼ä¸­æŒ‡å®šå®ƒçš„å®Œæ•´è·¯å¾‘ã€‚
æ­¥é©Ÿ 2ï¼šå®Œæ•´ Python ç¨‹å¼ç¢¼
ä¸‹æ–¹æ˜¯å®Œæ•´çš„ Python ç¨‹å¼ç¢¼ã€‚å®ƒæœƒè‡ªå‹•åŸ·è¡Œæ‰€æœ‰æ­¥é©Ÿï¼šæå–éŸ³è¨Š -> ç”¢ç”Ÿ SRT -> åˆä½µå½±ç‰‡ã€‚

è«‹å°‡æ­¤ç¨‹å¼ç¢¼å„²å­˜ç‚º Vosk.pyã€‚
"""
MODEL_PATH = "vosk-model-cn-0.22" 
# æ¯ä¸€å€‹å­—å¹•å¡ŠåŒ…å«çš„æœ€å¤§è©èªæ•¸é‡
MAX_WORDS_PER_LINE = 15

def format_time(seconds):
    """å°‡ç§’æ•¸è½‰æ›ç‚º SRT çš„æ™‚é–“æ ¼å¼ (HH:MM:SS,ms)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    seconds_rem = seconds % 60
    milliseconds = int((seconds_rem - int(seconds_rem)) * 1000)
    return f"{hours:02}:{minutes:02}:{int(seconds_rem):02},{milliseconds:03}"

def generate_srt(video_file):
    """å¾å½±ç‰‡æª”ç”¢ç”Ÿ SRT å­—å¹•æª”"""
    
    video_basename = os.path.basename(video_file)
    audio_file = f"temp_{video_basename}.wav"
    srt_file = f"{os.path.splitext(video_basename)[0]}.srt"

    # 1. æå–éŸ³è¨Š (ä½¿ç”¨ FFmpeg)
    # å°‡å½±ç‰‡è½‰ç‚º 16000Hz å–®è²é“ WAV æ ¼å¼ï¼Œé€™æ˜¯ Vosk æ¨è–¦çš„æ ¼å¼
    print(f"æ­¥é©Ÿ 1: å¾ '{video_file}' æå–éŸ³è¨Š...")
    ffmpeg_command = [
        'ffmpeg',
        '-y',  # è¦†è“‹å·²å­˜åœ¨çš„æª”æ¡ˆ
        '-i', video_file,
        '-ar', '16000',  # è¨­ç½®éŸ³è¨Šæ¡æ¨£ç‡ç‚º 16000Hz
        '-ac', '1',      # è¨­ç½®éŸ³è¨Šè²é“ç‚ºå–®è²é“
        '-f', 'wav',
        audio_file
    ]
    subprocess.run(ffmpeg_command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    print(f"éŸ³è¨Šå·²æå–è‡³ '{audio_file}'")

    # 2. èªéŸ³è¾¨è­˜ä¸¦ç”¢ç”Ÿ SRT å…§å®¹
    print("æ­¥é©Ÿ 2: ä½¿ç”¨ Vosk é€²è¡ŒèªéŸ³è¾¨è­˜...")
    if not os.path.exists(MODEL_PATH):
        print(f"éŒ¯èª¤: Vosk æ¨¡å‹è³‡æ–™å¤¾ '{MODEL_PATH}' ä¸å­˜åœ¨ã€‚")
        print("è«‹å¾ https://alphacephei.com/vosk/models ä¸‹è¼‰æ¨¡å‹ä¸¦æ”¾ç½®åœ¨æ­£ç¢ºè·¯å¾‘ã€‚")
        sys.exit(1)
        
    model = Model(MODEL_PATH)
    wf = wave.open(audio_file, "rb")
    rec = KaldiRecognizer(model, wf.getframerate())
    rec.SetWords(True)  # è¨­å®šç‚º True ä»¥ç²å–æ¯å€‹è©çš„æ™‚é–“æˆ³

    all_words = []
    while True:
        data = wf.readframes(4000)
        if len(data) == 0:
            break
        if rec.AcceptWaveform(data):
            result = json.loads(rec.Result())
            if 'result' in result:
                all_words.extend(result['result'])

    final_result = json.loads(rec.FinalResult())
    if 'result' in final_result:
        all_words.extend(final_result['result'])

    wf.close()
    
    # 3. å°‡è¾¨è­˜çµæœå¯«å…¥ SRT æª”æ¡ˆ
    print(f"æ­¥é©Ÿ 3: æ­£åœ¨ç”Ÿæˆ '{srt_file}'...")
    with open(srt_file, 'w', encoding='utf-8') as f:
        subtitle_index = 1
        
        for i in range(0, len(all_words), MAX_WORDS_PER_LINE):
            chunk = all_words[i : i + MAX_WORDS_PER_LINE]
            
            if not chunk:
                continue

            start_time = chunk[0]['start']
            end_time = chunk[-1]['end']
            text = " ".join(word['word'] for word in chunk)
            
            f.write(f"{subtitle_index}\n")
            f.write(f"{format_time(start_time)} --> {format_time(end_time)}\n")
            f.write(f"{text}\n\n")
            subtitle_index += 1
            
    print(f"'{srt_file}' å·²æˆåŠŸç”Ÿæˆï¼")
    return audio_file, srt_file

def main(video_file):
    if not os.path.exists(video_file):
        print(f"éŒ¯èª¤: å½±ç‰‡æª”æ¡ˆ '{video_file}' ä¸å­˜åœ¨ã€‚")
        return

    audio_file, srt_file = None, None
    try:
        # ç”¢ç”Ÿå­—å¹•
        audio_file, srt_file = generate_srt(video_file)
        
        # 4. åˆä½µå½±ç‰‡èˆ‡å­—å¹•
        output_video_file = f"{os.path.splitext(video_file)[0]}_subtitled.mp4"
        print(f"æ­¥é©Ÿ 4: æ­£åœ¨å°‡å­—å¹•åˆä½µè‡³ '{output_video_file}'...")

        # -c copy: ç›´æ¥è¤‡è£½å½±éŸ³æµï¼Œä¸é‡æ–°ç·¨ç¢¼ï¼Œé€Ÿåº¦æ¥µå¿«
        # -c:s mov_text: è¨­ç½®å­—å¹•ç·¨ç¢¼ï¼Œç›¸å®¹æ€§å¥½
        merge_command = [
            'ffmpeg',
            '-y',
            '-i', video_file,
            '-i', srt_file,
            '-c', 'copy',
            '-c:s', 'mov_text',
            output_video_file
        ]
        subprocess.run(merge_command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        print("ğŸ‰ å½±ç‰‡èˆ‡å­—å¹•åˆä½µå®Œæˆï¼")

    except Exception as e:
        print(f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        
    finally:
        # 5. æ¸…ç†æš«å­˜æª”æ¡ˆ
        print("æ­¥é©Ÿ 5: æ¸…ç†æš«å­˜æª”æ¡ˆ...")
        if audio_file and os.path.exists(audio_file):
            os.remove(audio_file)
            print(f"å·²åˆªé™¤æš«å­˜éŸ³è¨Šæª”: '{audio_file}'")
        # å¯ä»¥é¸æ“‡ä¿ç•™ srt æª”æ¡ˆæˆ–åˆªé™¤å®ƒ
        # if srt_file and os.path.exists(srt_file):
        #     os.remove(srt_file)
        #     print(f"å·²åˆªé™¤æš«å­˜å­—å¹•æª”: '{srt_file}'")


if __name__ == '__main__':
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python create_subtitles.py <æ‚¨çš„å½±ç‰‡æª”æ¡ˆ.mp4>")
        sys.exit(1)
        
    video_path = sys.argv[1]
    main(video_path)